# Titanic
Kaggle---Titanic: Machine Learning from Disaster   
https://www.kaggle.com/c/titanic

# Data Cleaning  
NUll values--  
Replaced null values with mean  
  
Categorical values--  
Used One hot encoding for the feature - 'Embarked' 

# Feature Selection
Used correlation table -- heatmap()

# Do Not use Linear Regression for Classification  
I have used Linear regression just to see how bad it works for classification problem<br/>  
# Logistic Regression    
Logistic Regression gave me approximately around 78% of accuracy score<br/>
# Random Forest    
While random forest gave around 82%<br/><br/>
# Compare other classification models    
I even compared different classification algorithm such as.-<br/>
  1. KNeighborsClassifier<br/>
  2. SVC<br/>
  3. DecisionTreeClassifier<br/>
  4. RandomForestClassifier<br/>
  5. AdaBoostClassifier<br/>
  6. GradientBoostingClassifier<br/>
  7. GaussianNB<br/>
  8. LinearDiscriminantAnalysis<br/>
  9. QuadraticDiscriminantAnalysis<br/>
  10. LogisticRegression
